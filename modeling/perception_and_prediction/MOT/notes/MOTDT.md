# 1809.04427 MOTDT

MOTDT是基于DEEPSORT的改进。

MOT目标跟踪领域一个亟待解决的问题是：如何将不可靠的检测结果与已经跟踪的目标轨迹进行关联。

本文基于TBD范式提出从检测结果和跟踪结果中收集候选框从而解决上面的检测不可靠的问题。

## 轨迹混合匹配

**1. 分级数据关联**

相较于DEEPSORT的基于轨迹漂移帧数的级联匹配机制，为解决上述问题，MOTDT所使用的是“轨迹混合匹配”的机制，即先将**当前帧检测器的检测结果**和轨迹的**Kalman滤波先验预测结果**进行混合生成**候选区域**（Candidates），共同作为当前帧目标状态的检测值，再与前一帧传播而来的**轨迹**依次依据**外观特征**（Re-ID feature）和**空间特征**（交并比IOU）进行**分级数据关联**。算法流程如下图所示：

![](.\Picture\MOTDT\MOTDT.jpg)

- **问：为什么要将Kalman滤波的预测和Detections进行混合得到一个候选区域呢？**

  答：作者认为，在不同的情况下，检测和跟踪是可以相互弥补的。基于Kalman滤波的预测往往在目标运动状态变化不剧烈的时候预测效果很好，即使目标存在短期的遮挡，只要遮挡时间不超过1个帧，由于相邻帧目标状态的冗余性质，Kalman滤波对目标状态的预测效果都是可靠的，此时就可以将Kalman滤波的先验预测作为该目标在当前时刻的目标状态；但是在目标运动状态变化十分剧烈，或者目标被遮挡时间过长的情况下，由于运动不确定性的扩散，此时Kalman滤波的预测就会变得极其不可靠，因此此时会引入Re-id特征进行相似距离匹配，来弥补Kalman滤波的不可靠性。因此，检测值和轨迹预测值实际上是一个“互补”的过程。

  比如：可靠性较高的检测在长时间（long-term）跟踪中可以防止跟踪漂移，而单纯的跟踪预测则可以避免因为遮挡出现的错漏检测而导致的匹配失败。所以，基于检测结果和跟踪结果生成的候选区域，可以较完备的体现跟踪目标可能出现的位置。

**2. Re-ID外观特征表达**

MOTDT上基本沿用了DEEPSORT中基于外观特征的数据关联（Re-ID），匹配的方式是相似距离匹配+马氏距离调节。

> Re-ID特征通常是一个分类网络，训练时，数据集中有N个身份的人，则网络的分类数即为N+1。训练完成后，该网络得到了泛化的可以识别同一个人外观特征的能力。去除最后分类用的全连接层，即只利用该网络做特征提取不进行后续分类。
>
> 在应用时，已有一个人的图像P，要判断另一张图像Q中的人是否有相同的特征，操作如下：
>
> （1）将P和Q分别送入Re-ID网络，提取特征向量
>
> （2）计算特征向量的距离d（欧式距离、余弦距离）
>
> （3）若d>m，则是两张图中的人有相同的身份；否则，身份不同
>
> 其中，m是阈值。

## 评分机制和NMS

MOTDT的另一个创新点在于引入了**轨迹评分机制**，使用**深度神经网络**来完成候选框的打分，时间越久的轨迹可信度就越高，基于这个评分就可以把轨迹产生的预测框和检测框放在一起做一个**NMS**，相当于是用预测弥补了漏检。

**1. 评分函数**

评估所有的候选框采用一个统一的**评分函数**，这个函数由一个判别训练的**目标分类器**和一个**轨迹段置信度计算模块**构成。

- **目标分类器**采用了R-FCN（基于区域的全卷积网络）来构建，该结构在整个图像上共享大多数计算，因此它比那些在图像块上进行分类的结构高效得多。该网络如下图所示：

![](.\Picture\MOTDT\R-FCN.png)

给定一帧图像， Score maps通过全卷积得到，每个候选框都可以定义出一个RoI（感兴趣区域，Region of Interest）：$(x_0,y_0,w,h)$，其中$(x_0,y_0)$表示左上角坐标，$w,h$分别表示宽与高。

为了计算的高效，作者希望每个RoI的分类概率可以通过共享的score maps投票得到。于是有个简单且直接的投票策略，就是为图像上的所有点构造前景概率, 然后计算RoI内的点的平均概率。然而这个简单的策略其实放弃了空间信息，如果ROI只覆盖到目标对象的一部分，事实上计算出来的ROI内点平均概率就将没有覆盖的部分的概率计算给忽视掉了；这就导致得到的信息不全，结果就会产生误差。

为了显式地将空间信息编码进score maps中，作者采用了位置敏感的RoI pooling层。采用RFCN网络的位置切分，将一个ROI区域$x$拆成$k\times k$的网格形状，每个网格对应类别的特定位置。作者从$k\times k$的网格中提取出响应值，则对于$x$这个ROI区域，最终分类概率公式化就是：

![classification probability](.\Picture\MOTDT\classification probability.png)

其中$z_i$表示第$i$个bin（网格中的方格，即有$k^2$个）的score map，$\sigma(x) = 1/(1+e^{-x})$是一个sigmoid函数。

在训练的时候，随机采取来自Ground truth周围的ROI作为正样本，并同时采用来自背景的相同数量的ROI作为负样本。

> 注意到这个网络设计的目的只是对检测出来的目标进行分类，所以空间位置不是它关注的重点。

- **轨迹段置信度计算模块**

前面我们知道，对于当前帧，用卡尔曼滤波来估计现有轨迹在该帧上的位置，可以一定程度上解决遮挡等造成的错误检测，但是卡尔曼滤波并不适用于长期跟踪，因为长时间不使用检测来更新卡尔曼滤波器的话，它的准确率会大大下降。因此，设计了轨迹段置信度计算模块来评估使用时序信息的卡尔曼滤波器的准确率。

作者提出通过连续帧中的候选对象的时间关联生成跟踪。一个轨迹段是连续帧上候选框关联形成的，可以将一个目标的完整轨迹拆分为多个轨迹段，因为一个轨迹可以在其生命周期内多次中断和恢复。每次一个轨迹从丢失状态恢复的时候，卡尔曼滤波器会被重新初始化。因此，最后一个轨迹段的信息被用来进行计算轨迹段的置性度。定义$L_{det}$为关联到这个轨迹段的**检测框数量**，$L_{trk}$为在这个轨迹段上最后一次检测关联后的**预测框数量**，则轨迹段置信度公式为：
$$
s_{trk}=\max(1-\log(1+\alpha·L_{trk}),0)·1(L_{det}\geq2)
$$
上式中的$1(L_{det}\geq2)$表示至少有两个关联到该轨迹段的检测框的轨迹才是合理的候选框。

- **统一的评分函数**

将上面的目标分类器得到的分类置信度和轨迹段置信度计算模块得到的置信度结合起来，构建出统一的评分函数如下：
$$
s=p(y|z,x)·(1(x\in C_{det}))+s_{trk}·(1(x\in C_{trk}))
$$
其中$C_{det}$表示来自检测框的候选框，$C_{trk}$表示来自跟踪预测框的候选框。

通过这个评分函数得到的分数送入NMS算法进行候选框选择。

**2. NMS**（non_max_suppression）：非极大值抑制，用来去除候选框中的冗余。

算法流程：

1. 给出一张图片和上面许多物体检测的候选框（即每个框可能都代表某种物体），但是这些框很可能有互相重叠的部分，我们要做的就是只保留最优的框。假设有N个框，每个框被分类器计算得到的分数为Si, 1<=i<=N。
2. 建造一个存放待处理候选框的集合H，初始化为包含全部N个框；建造一个存放最优框的集合M，初始化为空集。
3. 将所有集合 H 中的框进行排序，选出分数最高的框 m，从集合 H 移到集合 M；
4. 遍历集合 H 中的框，分别与框m计算交并比，如果高于阈值，则认为此框与m重叠，将此框从集合 H 中去除。
5. 回到第2步进行迭代，直到集合 H 为空。集合 M 中的框为我们所需。

## 结果分析

[GitHub - longcw/MOTDT：通过深度学习的候选人选择和人员重新识别进行实时多人跟踪](https://github.com/longcw/MOTDT)

尝试去运行了源代码，但是因为时代原因，以及可能是各种库以及python语言的特性更新，导致代码并不能在我的电脑上成功跑起来。

于是下面就简单分析下论文里的实验结果。

- 首先是对各个组件效果的对比：

  ![different components](.\Picture\MOTDT\different components.png)

  其中C表示目标分类器，T表示轨迹段置信度计算，A表示外观特征。可以看到每个部分的效果都是很明显的。

- 然后通过比较表现了Re-ID模型的效果：

  ![ReID-MOTDT](.\Picture\MOTDT\ReID-MOTDT.png)

- 最后整体在MOT16数据集上测试，效果优秀：

  ![MOTDT on MOT16](.\Picture\MOTDT\MOTDT on MOT16.png)

## 总结

MOTDT的大致流程为：收集候选项->选择候选项（目标分类器+轨迹段置信度计算模块=评分函数）->消除冗余->分层数据关联（Re-ID+IOU）->创建新的轨迹。

主要贡献有：

1）利用**深度神经网络**来选择候选项，从而解决不可靠的检测问题。

2）提出了**分层数据关联**模式，该模式利用了外观特征（Re-ID）和空间特征（IOU）。

>  2023.10.13 211220031 张佳瑞 第二次更新至此

