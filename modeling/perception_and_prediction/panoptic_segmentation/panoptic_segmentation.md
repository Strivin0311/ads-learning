# Introduction
在正式开始本文的内容前，作者首先阐述了目前全景分割领域的一些情况：  
1.    对于不规则、不可数的物体（**stuff**）的研究通常被划分到*语义分割*（**semantic segmentation**）任务中，且此类任务往往采用逐像素分类的方法解决；
2.    对于可数物体（**things**）的研究通常被划分到*物体检测*（**object detection**）或*实例分割*（**instance segmentation**）任务之中，这类任务往往采用*边界框*（bounding box）或*分割掩码*（segmentation mask）来完成检测和描绘任务。

尽管主流的思想将语义分割与实例分割当作两种截然不同的任务来处理，本文的作者却想将它们联系起来，总结成一个任务，他将其命名为*全景分割*（**panoptic segmentation**）。

在进行全景分割时，作者采用的方式是为每个像素分配一个类标签和实例id，类标签与实例id完全相同的像素可以确定一个物体（*需要注意的是，stuff的实例id无意义*）；关于衡量指标的制定，作者认为许多流行的衡量指标只适用于语义分割或实例分割任务中的一种，正是这种不相交的评判标准导致了两种研究的割裂，于是他制定了*全景质量*（**panoptic quality**）（PQ）这个统一的指标用于同时评判两种工作（或者是统一起来的全景分割任务）的完成情况。
# Format
在为每个像素分配类标签与实例id时的具体操作如下：  
首先给定由$L^{st}$(包含所有stuff类)和$L^{th}$(包含所有things类)组成的的类总集合L，全景分割任务需要为图像中的每个像素i计算出一个类标签-实例id对($l_i,z_i$)，其中，$l_i$∈L、$z_i$唯一标识同一类中的某个物体。
# Metric
在制定评估指标时，本文作者强调了指标量应该具有的以下三个要点：完整性、可解释性以及简易性，即以统一的方法评估stuff与things两类实体，并确保评估指标易于理解、计算与重现，为评估工作带来高效和便利。  
具体来说，作者从*分割匹配*（**segment matching**）与*基于匹配的PQ计算*（**PQ computation given the matches**）这两个部分来进行评估工作：
## Segment Matching
经过推理证明，作者得出一个在全景分割背景下适用的*匹配判定定理*:

$\underline{给定一个\textit{基准事实划分}（ground\ \ truth\ \ segment）p与预测划分q，p与q匹配当且仅当IoU(q,p)\geq0.5，并且这样的匹配最多只有一对}$

需要注意的是，IoU<0.5的匹配情况也是存在的，不过这种情况在实际运用中比较少见。
## PQ Computation
基于上一部分提到的唯一匹配知识，预测划分和基准事实划分被分成了三个部分：*真阳性*（**true positives (TP)**）对、*假阳性*（**false positives (FP)**）部分以及*假阴性*（**false negatives (FN)**）部分；其中，真阳性对指的是一对互相匹配的预测片段和基准事实片段、假阳性部分指没有匹配的预测片段、假阴性部分指没有匹配的基准事实片段。

有了TP、FP与FN的定义，PQ被定义为：
$$
PQ=\frac{\sum_{(p,g)\in TP}IoU(p,g)}{|TP|+\frac{1}{2}|FP|+\frac{1}{2}|FN|}.
$$

---

除了PQ的定义，作者还额外说明了*无效类*（void labels）与*组类*（group labels）的处理方式：  
对于$\underline{类外像素与模糊未知的像素}$，即无效类的像素，有两条处理原则： 
1.    基准事实中被分类为void的像素不参与匹配与IoU的计算；
2.    在完成匹配后，含有一部分超过匹配阈值的无效类像素的预测片段被剔除，不作为FP参与计算。

在进行实际的注解工作时,$\underline{当两个临近实体的类别相同且难以给出具体的实例id时}$，往往使用组类进行注解，这类像素就叫作组类像素。对于组类像素，同样有两条处理原则：  
1.    组类像素不参与匹配；
2.    在完成匹配后，含有一部分来自同一类的超过匹配阈值的组像素的预测片段被剔除，不作为FP参与计算。

---