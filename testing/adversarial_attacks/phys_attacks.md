# Physical-World Adversarial Attacks
*Here're some resources about Physical-World Adversarial Attacks*

Intros:

* Physical-world adversarial attacks involve manipulating real-world objects to deceive AVs. For instance, subtly altering road signs so that they’re misinterpreted by an AV’s vision system, causing incorrect or dangerous actions.

---


#### Physically Realizable Targeted Adversarial Attacks on Autonomous Driving

paper link: [here](https://keep.lib.asu.edu/_flysystem/fedora/c7/Buddareddygari_asu_0010N_20802.pdf)

citation: 
```bibtex
@phdthesis{buddareddygari2021physically,
  title={Physically Realizable Targeted Adversarial Attacks on Autonomous Driving},
  author={Buddareddygari, Prasanth},
  year={2021},
  school={Arizona State University}
}
```

#### Dirty road can attack: Security of deep learning based automated lane centering under {Physical-World} attack

paper link: [here](https://www.usenix.org/system/files/sec21-sato.pdf)

citation: 
```bibtex
@inproceedings{sato2021dirty,
  title={Dirty road can attack: Security of deep learning based automated lane centering under $\{$Physical-World$\}$ attack},
  author={Sato, Takami and Shen, Junjie and Wang, Ningfei and Jia, Yunhan and Lin, Xue and Chen, Qi Alfred},
  booktitle={30th USENIX Security Symposium (USENIX Security 21)},
  pages={3309--3326},
  year={2021}
}
```

#### Invisible for both camera and lidar: Security of multi-sensor fusion based perception in autonomous driving under physical-world attacks

paper link: [here](https://arxiv.org/pdf/2106.09249)

citation: 
```bibtex
@inproceedings{cao2021invisible,
  title={Invisible for both camera and lidar: Security of multi-sensor fusion based perception in autonomous driving under physical-world attacks},
  author={Cao, Yulong and Wang, Ningfei and Xiao, Chaowei and Yang, Dawei and Fang, Jin and Yang, Ruigang and Chen, Qi Alfred and Liu, Mingyan and Li, Bo},
  booktitle={2021 IEEE Symposium on Security and Privacy (SP)},
  pages={176--194},
  year={2021},
  organization={IEEE}
}
```

#### Multi-source adversarial sample attack on autonomous vehicles

paper link: [here](https://par.nsf.gov/servlets/purl/10230090)

citation: 
```bibtex
@article{xiong2021multi,
  title={Multi-source adversarial sample attack on autonomous vehicles},
  author={Xiong, Zuobin and Xu, Honghui and Li, Wei and Cai, Zhipeng},
  journal={IEEE Transactions on Vehicular Technology},
  volume={70},
  number={3},
  pages={2822--2835},
  year={2021},
  publisher={IEEE}
}
```
    
#### Physgan: Generating physical-world-resilient adversarial examples for autonomous driving

paper link: [here](https://openaccess.thecvf.com/content_CVPR_2020/papers/Kong_PhysGAN_Generating_Physical-World-Resilient_Adversarial_Examples_for_Autonomous_Driving_CVPR_2020_paper.pdf)

citation: 
```bibtex
@inproceedings{kong2020physgan,
  title={Physgan: Generating physical-world-resilient adversarial examples for autonomous driving},
  author={Kong, Zelun and Guo, Junfeng and Li, Ang and Liu, Cong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={14254--14263},
  year={2020}
}
```
     
    

#### Simple physical adversarial examples against end-to-end autonomous driving models

paper link: [here](https://arxiv.org/pdf/1903.05157)

citation: 
```bibtex
@inproceedings{boloor2019simple,
  title={Simple physical adversarial examples against end-to-end autonomous driving models},
  author={Boloor, Adith and He, Xin and Gill, Christopher and Vorobeychik, Yevgeniy and Zhang, Xuan},
  booktitle={2019 IEEE International Conference on Embedded Software and Systems (ICESS)},
  pages={1--7},
  year={2019},
  organization={IEEE}
}
```
